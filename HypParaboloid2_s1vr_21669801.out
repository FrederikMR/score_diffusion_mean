Loaded dependency [python3/3.10.12]: gcc/11.4.0-binutils-2.40
Loaded dependency [python3/3.10.12]: sqlite3/3.42.0

Switching from python3/3.8.2 to python3/3.10.12
  Loading requirement: gcc/11.4.0-binutils-2.40 sqlite3/3.42.0
2024-05-02 19:05:33.693777: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-05-02 19:05:33.693823: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-05-02 19:05:33.699317: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
using M.Exp for Logarithm
Epoch: 100 	 loss = -1003.1475
Epoch: 200 	 loss = -1003.6227
Epoch: 300 	 loss = -998.4342
Epoch: 400 	 loss = -1000.4302
Epoch: 500 	 loss = -1002.6946
Epoch: 600 	 loss = -1002.1209
Epoch: 700 	 loss = -1004.6490
Epoch: 800 	 loss = -1000.5208
Epoch: 900 	 loss = -1001.2539
Epoch: 1000 	 loss = -1000.7457
Epoch: 1100 	 loss = -1001.3824
Epoch: 1200 	 loss = -1004.5928
Epoch: 1300 	 loss = -1004.2502
Epoch: 1400 	 loss = -998.5670
Epoch: 1500 	 loss = -1001.9803
Epoch: 1600 	 loss = -1004.2743
Epoch: 1700 	 loss = -1000.6395
Epoch: 1800 	 loss = -999.0703
Epoch: 1900 	 loss = -1003.7900
Epoch: 2000 	 loss = -1001.2964
Epoch: 2100 	 loss = -1000.6877
Epoch: 2200 	 loss = -1002.8928
Epoch: 2300 	 loss = -1000.7622
Epoch: 2400 	 loss = -1001.6354
Epoch: 2500 	 loss = -1005.4863
Epoch: 2600 	 loss = -1001.4242
Epoch: 2700 	 loss = -1001.7817
Epoch: 2800 	 loss = -1002.4368
Epoch: 2900 	 loss = -1002.7521
Epoch: 3000 	 loss = -1001.6686
Traceback (most recent call last):
  File "/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/train_score.py", line 290, in <module>
    train_score()
  File "/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/train_score.py", line 268, in train_score
    train_s1(M=M,
  File "/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/jaxgeometry/statistics/score_matching/trainxt.py", line 106, in train_s1
    data = next(train_dataset)
  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_utils.py", line 82, in _eager_dataset_iterator
    for elem in ds:
  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py", line 809, in __next__
    return self._next_internal()
  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py", line 772, in _next_internal
    ret = gen_dataset_ops.iterator_get_next(
  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py", line 3023, in iterator_get_next
    _result = pywrap_tfe.TFE_Py_FastPathExecute(
KeyboardInterrupt
terminate called without an active exception
/zhome/77/8/118225/.lsbatch/1714653379.21669801.shell: line 36: 11213 Aborted                 python3 train_score.py --manifold HypParaboloid --dim 2 --s1_loss_type dsmvr --s2_loss_type dsmvr --load_model 0 --T_sample 0 --t 0.01 --train_net s1 --max_T 1.0 --lr_rate 0.0002 --epochs 50000 --x_samples 64 --t_samples 256 --repeats 16 --samples_per_batch 32 --dt_steps 1000 --save_step 100 --seed 2712
