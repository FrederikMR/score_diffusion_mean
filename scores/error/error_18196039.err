Switching from python to 3/3.9.11
  ERROR: Unable to locate a modulefile for '3/3.9.11'
2023-10-11 02:05:47.604442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
2023-10-11 02:07:48.784864: E external/xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:

  %reduce-window.42 = f32[1024,55]{1,0} reduce-window(f32[32768,55]{1,0} %broadcast.265, f32[] %constant.22), window={size=32x1 stride=32x1}, to_apply=%region_5.902

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2023-10-11 02:07:49.458897: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.674124143s
Constant folding an instruction is taking > 1s:

  %reduce-window.42 = f32[1024,55]{1,0} reduce-window(f32[32768,55]{1,0} %broadcast.265, f32[] %constant.22), window={size=32x1 stride=32x1}, to_apply=%region_5.902

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
Terminated
