Loaded dependency [python3/3.10.12]: gcc/11.4.0-binutils-2.40
Loaded dependency [python3/3.10.12]: sqlite3/3.42.0

Switching from python3/3.8.2 to python3/3.10.12
  Loading requirement: gcc/11.4.0-binutils-2.40 sqlite3/3.42.0
2024-02-22 02:15:13.750861: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-22 02:15:13.750951: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-22 02:15:13.767675: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
/zhome/77/8/118225/.local/lib/python3.10/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/zhome/77/8/118225/.local/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
2024-02-22 02:16:00.824155: E external/xla/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:

  %reduce.11 = f32[262144,10]{1,0} reduce(f32[262144,10,10]{2,1,0} %broadcast.210, f32[] %constant.63), dimensions={1}, to_apply=%region_2.729, metadata={op_name="jit(update)/jit(main)/transpose(jvp(jit(loss_fun)))/reduce_sum[axes=(1,)]" source_file="/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/jaxgeometry/statistics/score_matching/trainxt.py" source_line=231}

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2024-02-22 02:16:05.675490: E external/xla/xla/service/slow_operation_alarm.cc:133] The operation took 5.851430356s
Constant folding an instruction is taking > 1s:

  %reduce.11 = f32[262144,10]{1,0} reduce(f32[262144,10,10]{2,1,0} %broadcast.210, f32[] %constant.63), dimensions={1}, to_apply=%region_2.729, metadata={op_name="jit(update)/jit(main)/transpose(jvp(jit(loss_fun)))/reduce_sum[axes=(1,)]" source_file="/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/jaxgeometry/statistics/score_matching/trainxt.py" source_line=231}

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime. XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
