Loaded dependency [python3/3.10.12]: gcc/11.4.0-binutils-2.40
Loaded dependency [python3/3.10.12]: sqlite3/3.42.0

Switching from python3/3.8.2 to python3/3.10.12
  Loading requirement: gcc/11.4.0-binutils-2.40 sqlite3/3.42.0
2024-02-27 22:44:46.671704: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-27 22:44:46.671747: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-27 22:44:46.683972: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
/zhome/77/8/118225/.local/lib/python3.10/site-packages/numpy/core/getlimits.py:518: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  setattr(self, word, getattr(machar, word).flat[0])
/zhome/77/8/118225/.local/lib/python3.10/site-packages/numpy/core/getlimits.py:89: UserWarning: The value of the smallest subnormal for <class 'numpy.float32'> type is zero.
  return self._float_to_str(self.smallest_subnormal)
2024-02-27 22:45:25.777384: W external/xla/xla/service/gpu/runtime/support.cc:58] Intercepted XLA runtime error:
INTERNAL: Failed to launch CUDA kernel: triton_gemm_dot with block dimensions: 128x1x1 and grid dimensions: 16x1x4 and shared memory size: 65536: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2024-02-27 22:45:25.871034: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: XlaRuntimeError: INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.func.launch' failed: Failed to launch CUDA kernel: triton_gemm_dot with block dimensions: 128x1x1 and grid dimensions: 16x1x4 and shared memory size: 65536: CUDA_ERROR_OUT_OF_MEMORY: out of memory; current tracing scope: triton_gemm_dot; current profiling annotation: XlaModule:#hlo_module=extracted,program_id=86#.
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py", line 270, in __call__
    ret = func(*args)

  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 643, in wrapper
    return func(*args, **kwargs)

  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py", line 198, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/jaxgeometry/statistics/score_matching/generators.py", line 423, in __call__
    (ts,xss,chartss,*_) = self.product((jnp.repeat(self.x0s[0],self.x_samples,axis=0),

jaxlib.xla_extension.XlaRuntimeError: INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.func.launch' failed: Failed to launch CUDA kernel: triton_gemm_dot with block dimensions: 128x1x1 and grid dimensions: 16x1x4 and shared memory size: 65536: CUDA_ERROR_OUT_OF_MEMORY: out of memory; current tracing scope: triton_gemm_dot; current profiling annotation: XlaModule:#hlo_module=extracted,program_id=86#.


Traceback (most recent call last):
  File "/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/train_score.py", line 346, in <module>
    train_score()
  File "/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/train_score.py", line 324, in train_score
    train_s1(M=M,
  File "/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/jaxgeometry/statistics/score_matching/trainxt.py", line 94, in train_s1
    initial_params = model.init(jrandom.PRNGKey(seed), next(train_dataset)[:,:(2*N_dim+1)])
  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow_datasets/core/dataset_utils.py", line 82, in _eager_dataset_iterator
    for elem in ds:
  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py", line 809, in __next__
    return self._next_internal()
  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/iterator_ops.py", line 772, in _next_internal
    ret = gen_dataset_ops.iterator_get_next(
  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_dataset_ops.py", line 3028, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py", line 5888, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.UnknownError: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} XlaRuntimeError: INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.func.launch' failed: Failed to launch CUDA kernel: triton_gemm_dot with block dimensions: 128x1x1 and grid dimensions: 16x1x4 and shared memory size: 65536: CUDA_ERROR_OUT_OF_MEMORY: out of memory; current tracing scope: triton_gemm_dot; current profiling annotation: XlaModule:#hlo_module=extracted,program_id=86#.
jax.errors.SimplifiedTraceback: For simplicity, JAX has removed its internal frames from the traceback of the following exception. Set JAX_TRACEBACK_FILTERING=off to include these.


The above exception was the direct cause of the following exception:


Traceback (most recent call last):

  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py", line 270, in __call__
    ret = func(*args)

  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py", line 643, in wrapper
    return func(*args, **kwargs)

  File "/zhome/77/8/118225/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py", line 198, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File "/zhome/77/8/118225/Desktop/Projects/score_diffusion_mean/score_diffusion_mean/jaxgeometry/statistics/score_matching/generators.py", line 423, in __call__
    (ts,xss,chartss,*_) = self.product((jnp.repeat(self.x0s[0],self.x_samples,axis=0),

jaxlib.xla_extension.XlaRuntimeError: INTERNAL: Failed to execute XLA Runtime executable: run time error: custom call 'xla.gpu.func.launch' failed: Failed to launch CUDA kernel: triton_gemm_dot with block dimensions: 128x1x1 and grid dimensions: 16x1x4 and shared memory size: 65536: CUDA_ERROR_OUT_OF_MEMORY: out of memory; current tracing scope: triton_gemm_dot; current profiling annotation: XlaModule:#hlo_module=extracted,program_id=86#.


	 [[{{node PyFunc}}]] [Op:IteratorGetNext] name: 
